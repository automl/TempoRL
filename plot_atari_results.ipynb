{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils.plotting import get_colors, load_config, plot\n",
    "from utils.data_handling import load_dqn_data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name explanations\n",
    "* DQN -> standard DQN\n",
    "* DAR_min^max -> Dynamic action repetition with small repetition and long repetition values\n",
    "* tqn -> TempoRL DQN with separate skip-DQN that expects the behaviour action to be concatenated to the state\n",
    "* t-dqn -> TempoRL DQN with separate skip-DQN that expects the behaviour action as contextual input\n",
    "* tdqn -> TempoRL DQN with shared state representation between the behavoiur and skip action outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "from scipy.signal import savgol_filter\n",
    "    \n",
    "\n",
    "# Somehow the plotting functionallity I ended up with was already covered for the tabular case.\n",
    "# I should have just used the plot function from that.\n",
    "def plotMultiple(data, ylim=None, title='', logStepY=False, max_steps=200, xlim=None, figsize=None,\n",
    "                 alphas=None, smooth=5, savename=None, rewyticks=None, lenyticks=None,\n",
    "                 skip_stdevs=[], dont_label=[], dont_plot=[], min_steps=None,\n",
    "                 logRewY=False):\n",
    "    \"\"\"\n",
    "    Simple plotting method that shows the test reward on the y-axis and the number of performed training steps\n",
    "    on the x-axis.\n",
    "    \n",
    "    data -> (dict[agent name] -> list([rewards, lens, decs, train_steps, train_episodes])) the data to plot\n",
    "    ylim -> (list) y-axis limit\n",
    "    title -> (str) title on top of plot\n",
    "    logStepY -> (bool) flag that indicates if the y-axis should be on log scale.\n",
    "    max_steps -> (int) maximal episode length\n",
    "    min_steps -> (int) optional minimum episode length. If not set assumes 1 as min\n",
    "    xlim -> (list) x-axis limits\n",
    "    figsize -> (list) dimensions of the figure\n",
    "    alphas -> (dict[agent name] -> float) the alpha value to use for plotting of specific agents\n",
    "    smooth -> (int) the window size for smoothing (has to be odd if used. < 0 deactivates this option)\n",
    "    savename -> (str) filename to save the figure\n",
    "    rewyticks -> (list) yticks for the reward plot\n",
    "    lenyticks -> (list) yticks for the decisions plot\n",
    "    skip_sdevs -> (list) list of names to not plot standard deviations for.\n",
    "    dont_label -> (list) list of names to not label.\n",
    "    dont_plot -> (list) list of names to not plot.\n",
    "    logRewY -> (bool) flag that indicates if the reward y-axis should be on log scale.\n",
    "    \"\"\"\n",
    "    \n",
    "    if smooth and smooth > 0:\n",
    "        degree = 2\n",
    "        for agent in data:\n",
    "            data[agent] = list(data[agent])  # we have to convert the tuple to lists\n",
    "            data[agent][0] = list(data[agent][0])\n",
    "            data[agent][0][0] = savgol_filter(data[agent][0][0], smooth, degree)  # smooth the mean reward\n",
    "            data[agent][0][1] = savgol_filter(data[agent][0][1], smooth, degree)  # smooth the stdev reward\n",
    "            data[agent][1] = list(data[agent][1])\n",
    "            data[agent][1][0] = savgol_filter(data[agent][1][0], smooth, degree)  # smooth mean num steps\n",
    "            data[agent][1][1] = savgol_filter(data[agent][1][1], smooth, degree)\n",
    "            data[agent][2] = list(data[agent][2])\n",
    "            data[agent][2][0] = savgol_filter(data[agent][2][0], smooth, degree)  # smooth mean decisions\n",
    "            data[agent][2][1] = savgol_filter(data[agent][2][1], smooth, degree)\n",
    "\n",
    "    colors, color_map = get_colors()\n",
    "    \n",
    "\n",
    "    cfg = load_config()\n",
    "    sb.set_style(cfg['plotting']['seaborn']['style'])\n",
    "    sb.set_context(cfg['plotting']['seaborn']['context']['context'],\n",
    "                   font_scale=cfg['plotting']['seaborn']['context']['font scale'],\n",
    "                   rc=cfg['plotting']['seaborn']['context']['rc2'])\n",
    "\n",
    "    if figsize:\n",
    "        fig, ax = plt.subplots(2, figsize=figsize, dpi=100, sharex=True)\n",
    "    else:\n",
    "        fig, ax = plt.subplots(2, figsize=(20, 10), dpi=100,sharex=True)\n",
    "    ax[0].set_title(title)\n",
    "\n",
    "    for agent in list(data.keys())[::-1]:\n",
    "        if agent in dont_plot:\n",
    "            continue\n",
    "        try:\n",
    "            alph = alphas[agent]\n",
    "        except:\n",
    "            alph = 1.\n",
    "        color_name = color_map['dar'] if 'dar' in agent else color_map[agent]\n",
    "        rew, lens, decs, train_steps, train_eps = data[agent]\n",
    "        \n",
    "        label = agent.upper()\n",
    "        if agent in ['t-dqn', 'tdqn', 'tqn']:\n",
    "            label = 't-DQN'\n",
    "        elif agent in dont_label:\n",
    "            label = None\n",
    "\n",
    "        #### Plot rewards\n",
    "        ax[0].step(train_steps[0], rew[0], where='post', c=colors[color_name], label=label,\n",
    "                   alpha=alph, ls='-' if agent != 't-dqn' else '-.')\n",
    "        if agent not in skip_stdevs:\n",
    "            ax[0].fill_between(train_steps[0], rew[0]-rew[1], rew[0]+rew[1],\n",
    "                               alpha=0.25 * alph, step='post',\n",
    "                               color=colors[color_name])\n",
    "        #### Plot lens\n",
    "        ax[1].step(train_steps[0], decs[0], where='post',\n",
    "                   c=np.array(colors[color_name]), ls='-',\n",
    "                   alpha=alph)\n",
    "        if agent not in skip_stdevs:\n",
    "            ax[1].fill_between(train_steps[0], decs[0]-decs[1], decs[0]+decs[1],\n",
    "                               alpha=0.125 * alph, step='post',\n",
    "                               color=np.array(colors[color_name]))\n",
    "        ax[1].step(train_steps[0], lens[0], where='post',\n",
    "                   c=np.array(colors[color_name]) * .75, alpha=alph,\n",
    "                   ls=':')\n",
    "        \n",
    "        if agent not in skip_stdevs:\n",
    "            ax[1].fill_between(train_steps[0], lens[0]-lens[1], lens[0]+lens[1],\n",
    "                               alpha=0.25 * alph, step='post',\n",
    "                               color=np.array(colors[color_name]) * .75)\n",
    "    #ax[0].semilogx()\n",
    "    if rewyticks is not None:\n",
    "        ax[0].set_yticks(rewyticks)\n",
    "    if ylim:\n",
    "        ax[0].set_ylim(ylim)\n",
    "    if xlim:\n",
    "        ax[0].set_xlim(xlim)\n",
    "    ax[0].set_ylabel('Reward')\n",
    "    if len(data) - len(dont_label) < 5:\n",
    "        ax[0].legend(ncol=1, loc='best', handlelength=.75)\n",
    "    ax[1].semilogx()\n",
    "    if logStepY:\n",
    "        ax[1].semilogy()\n",
    "    if logRewY:\n",
    "        ax[0].semilogy()\n",
    "        \n",
    "    ax[1].plot([-999, -999], [-999, -999], ls=':', c='k', label='all')\n",
    "    ax[1].plot([-999, -999], [-999, -999], ls='-', c='k', label='dec')\n",
    "    ax[1].legend(loc='best', ncol=1, handlelength=.75)\n",
    "    if not min_steps:\n",
    "        ax[1].set_ylim([1, max_steps])\n",
    "    else:\n",
    "        ax[1].set_ylim([min_steps, max_steps])\n",
    "    if xlim:\n",
    "        ax[1].set_xlim(xlim)\n",
    "    ax[1].set_ylabel('#Actions')\n",
    "    ax[1].set_xlabel('#Train Steps')\n",
    "    if lenyticks is not None:\n",
    "        ax[1].set_yticks(lenyticks)\n",
    "    plt.tight_layout()\n",
    "    if savename:\n",
    "        plt.savefig(savename)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_best_to_plot(data, aucs, tempoRL=None):\n",
    "    \"\"\"\n",
    "    Simple method to filter which lines to plot.\n",
    "    \"\"\"\n",
    "    to_plot = dict()\n",
    "\n",
    "    if tempoRL is None:\n",
    "        aucs = list(sorted(aucs, key=lambda x: x[1], reverse=True))\n",
    "        for idx, auc in enumerate(aucs):\n",
    "            if 't' in auc[0]:\n",
    "                break\n",
    "        to_plot[aucs[idx][0]] = data[aucs[idx][0]]  # the absolute best\n",
    "    else:\n",
    "        to_plot[tempoRL] = data[tempoRL]\n",
    "\n",
    "    bv = -np.inf\n",
    "    b = None\n",
    "    for elem in aucs:\n",
    "        if 'dar' not in elem[0]:\n",
    "            continue\n",
    "        elif elem[1] > bv:\n",
    "            b, bv = elem[0], elem[1]\n",
    "    to_plot[b] = data[b]\n",
    "    \n",
    "    \n",
    "    to_plot['dqn'] = data['dqn']\n",
    "    return to_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "data['tdqn'] = load_dqn_data('*', 'experiments/atari/pong/tdqn',\n",
    "                             #debug=True,\n",
    "                             max_steps=2.5*10**6)\n",
    "data['dqn'] = load_dqn_data('*', 'experiments/atari/pong/dqn',\n",
    "                            #debug=True,\n",
    "                            max_steps=2.5*10**6)\n",
    "data[r'dar$_{1}^{10}$'] = load_dqn_data('*', 'experiments/atari/pong/dar',\n",
    "                            #debug=True,\n",
    "                            max_steps=2.5*10**6)\n",
    "\n",
    "plotMultiple(data, title='Pong',\n",
    "             ylim=[-22, 22], xlim=[10**4, 2.5*10**6],\n",
    "             min_steps=10**2, max_steps=3000, lenyticks=[10**2, 10**3, 2*10**3, 3*10**3],\n",
    "             smooth=7, savename='pong_50_seeds.pdf')  #, logStepY=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "data['tdqn'] = load_dqn_data('*', 'experiments/atari/beam_rider/tdqn_3',\n",
    "                             #debug=True,\n",
    "                             max_steps=2.5*10**6)\n",
    "data['dqn'] = load_dqn_data('*', 'experiments/atari/beam_rider/dqn_3',\n",
    "                            #debug=True,\n",
    "                            max_steps=2.5*10**6)\n",
    "data[r'dar$_{1}^{10}$'] = load_dqn_data('*', 'experiments/atari/beam_rider/dar_3',\n",
    "                            #debug=True,\n",
    "                            max_steps=2.5*10**6)\n",
    "\n",
    "plotMultiple(data, title='BeamRider',\n",
    "             ylim=[0, 600],\n",
    "             xlim=[10**4, 2.5*10**6],\n",
    "             max_steps=1000, rewyticks=[0, 150, 300, 450, 600],  #lenyticks=[10**2, 10**3, 2*10**3, 3*10**3],\n",
    "             smooth=7, savename='beamrider_15_seeds.pdf')  #, logStepY=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "data['tdqn'] = load_dqn_data('*', 'experiments/atari/freeway/tdqn_3',\n",
    "                             #debug=True,\n",
    "                             max_steps=2.5*10**6)\n",
    "data['dqn'] = load_dqn_data('*', 'experiments/atari/freeway/dqn_3',\n",
    "                            #debug=True,\n",
    "                            max_steps=2.5*10**6)\n",
    "data[r'dar$_{1}^{10}$'] = load_dqn_data('*', 'experiments/atari/freeway/dar_3',\n",
    "                            #debug=True,\n",
    "                            max_steps=2.5*10**6)\n",
    "\n",
    "plotMultiple(data, title='Freeway',\n",
    "             ylim=[0, 35],\n",
    "             xlim=[10**4, 2.5*10**6],\n",
    "             max_steps=2100, rewyticks=[0, 11, 22, 33],  #lenyticks=[10**2, 10**3, 2*10**3, 3*10**3],\n",
    "             smooth=7, savename='freeway_15_seeds.pdf')  #, logStepY=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "data['tdqn'] = load_dqn_data('*', 'experiments/atari/ms_pacman/tdqn_3',\n",
    "                             #debug=True,\n",
    "                             max_steps=2.5*10**6)\n",
    "data['dqn'] = load_dqn_data('*', 'experiments/atari/ms_pacman/dqn_3',\n",
    "                            #debug=True,\n",
    "                            max_steps=2.5*10**6)\n",
    "data[r'dar$_{1}^{10}$'] = load_dqn_data('*', 'experiments/atari/ms_pacman/dar_3',\n",
    "                            #debug=True,\n",
    "                            max_steps=2.5*10**6)\n",
    "\n",
    "plotMultiple(data, title='MsPacman',\n",
    "             ylim=[0, 750],\n",
    "             xlim=[10**4, 2.5*10**6],\n",
    "             max_steps=300, rewyticks=[0, 250, 500, 750],  #lenyticks=[10**2, 10**3, 2*10**3, 3*10**3],\n",
    "             smooth=7, savename='mspacman_15_seeds.pdf')  #, logStepY=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "data['tdqn'] = load_dqn_data('*', 'experiments/atari/qbert_long/tdqn_3',\n",
    "                             #debug=True,\n",
    "                             max_steps=5*10**6)\n",
    "data['dqn'] = load_dqn_data('*', 'experiments/atari/qbert_long/dqn_3',\n",
    "                            #debug=True,\n",
    "                            max_steps=5*10**6)\n",
    "data[r'dar$_{1}^{10}$'] = load_dqn_data('*', 'experiments/atari/qbert_long/dar_3',\n",
    "                            #debug=True,\n",
    "                            max_steps=5*10**6)\n",
    "\n",
    "plotMultiple(data, title='QBert',\n",
    "             ylim=[0, 1000],\n",
    "             xlim=[10**4, 5*10**6], logRewY=False,\n",
    "             max_steps=225, min_steps=0, rewyticks=[0, 250, 500, 750, 1000], lenyticks=[0, 50, 100, 150, 200],\n",
    "             smooth=7, savename='qbert_15_sees.pdf')  #, logStepY=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "data['tdqn'] = load_dqn_data('*', 'experiments/atari/qbert/tdqn_3',\n",
    "                             #debug=True,\n",
    "                             max_steps=2.5*10**6)\n",
    "data['dqn'] = load_dqn_data('*', 'experiments/atari/qbert/dqn_3',\n",
    "                            #debug=True,\n",
    "                            max_steps=2.5*10**6)\n",
    "\n",
    "plotMultiple(data, title='QBert',\n",
    "             ylim=[0, 1000],\n",
    "             xlim=[10**4, 2.5*10**6], logRewY=False,\n",
    "             max_steps=225, min_steps=0, rewyticks=[0, 250, 500, 750, 1000], lenyticks=[0, 50, 100, 150, 200],\n",
    "             smooth=7)  #, logStepY=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
